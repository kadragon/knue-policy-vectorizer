# KNUE Policy Vectorizer Environment Configuration

# ðŸ”§ Provider Selection (Multi-Provider Support)
EMBEDDING_PROVIDER=ollama        # ollama, openai
VECTOR_PROVIDER=qdrant_local     # qdrant_local, qdrant_cloud

# Ollama Configuration (Local Embeddings)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=bge-m3              # Also: EMBEDDING_MODEL (legacy)

# OpenAI Configuration (Cloud Embeddings) - NEW
OPENAI_API_KEY=                  # Required when EMBEDDING_PROVIDER=openai
OPENAI_MODEL=text-embedding-3-small  # text-embedding-3-small, text-embedding-3-large
OPENAI_BASE_URL=https://api.openai.com/v1  # Optional, for custom endpoints

# Qdrant Local Configuration
QDRANT_URL=http://localhost:6333

# Qdrant Cloud Configuration (NEW)
QDRANT_CLOUD_URL=               # https://your-cluster.qdrant.tech
QDRANT_API_KEY=                 # Required when VECTOR_PROVIDER=qdrant_cloud

# Git Repository Configuration
GIT_REPO_URL=https://github.com/KNUE-CS/KNUE-Policy-Hub.git
GIT_BRANCH=main
REPO_CACHE_DIR=./repo_cache

# Collection Configuration
COLLECTION_NAME=knue_policies
VECTOR_SIZE=1024                 # Auto-adjusted based on provider: bge-m3(1024), openai-small(1536), openai-large(3072)

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=logs/vectorizer.log

# Processing Configuration
MAX_TOKEN_LENGTH=8192
MAX_DOCUMENT_CHARS=30000
CHUNK_THRESHOLD=800
CHUNK_OVERLAP=200
BATCH_SIZE=10

# Docker-specific overrides (when running in Docker)
# QDRANT_URL=http://qdrant:6333
# OLLAMA_URL=http://host.docker.internal:11434
